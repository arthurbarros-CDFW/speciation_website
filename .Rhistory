sonar_data<-readRDS("data/sonar_data.rds")
aux_data<-readRDS("data/aux_data.rds")
flow_df<-readRDS("data/flow_df.rds")
#create new simulated auxiliary length and date for species C.
#lengths
lengths_C <- rnorm(150, mean=110, sd=10)
#dates
dates_C <- round(rnorm(150,mean = as.numeric(as.Date("2024-03-15")), sd = 20))
#make dataframe
aux_dataC <- data.frame(
length = c(lengths_C),
date = round(as.Date(dates_C,origin = "1970-01-01")),
species = factor(rep("C", times=150))
)
#join in flow we created in last section
aux_dataC<-aux_dataC%>%
dplyr::left_join(flow_df,by="date")
aux_data<-aux_data%>%
rbind(aux_dataC)
library(gridExtra)
library(scales)
p_dates<-ggplot(aux_data) +
# Histogram for Date
geom_histogram(aes(x = date, fill = species), bins = 40) +
theme_classic()+
scale_fill_manual(values = c('darkorange2','cyan3','darkgreen'),
labels = c('A','B','C'))+
scale_x_date(date_breaks = "2 month",
labels=date_format("%b-%Y"),
limits = as.Date(c(min(aux_data$date),max(aux_data$date))))
p_lengths<-ggplot(aux_data) +
# Histogram for Length
geom_histogram(aes(x = length, fill = species), bins = 40) +
theme_classic()+
scale_fill_manual(values = c('darkorange2','cyan3','darkgreen'),
labels = c('A','B','C'))
p_flow<-ggplot(flow_df) +
# Histogram for Flow Conditions
geom_line(aes(x = date,y=Flow_cfs),
stat='identity') +
scale_x_date(date_breaks = "2 month",
labels=date_format("%b-%Y"),
limits = as.Date(c(min(aux_data$date),max(aux_data$date))))+
theme_classic()+
ylab("flow (cfs)")
grid.arrange(p_dates, p_lengths, p_flow)
#Simulate some example sonar data
#lengths
lengths_C <- rnorm(300, mean=110, sd=10)
#dates
dates_C <- round(rnorm(300,mean = as.numeric(as.Date("2024-03-15")), sd = 20))
#make dataframe
sonar_dataC <- data.frame(
length = c(lengths_C),
date = round(as.Date(dates_C,origin = "1970-01-01"))
)
#join in flow we created in last section
sonar_dataC<-sonar_dataC%>%
dplyr::left_join(flow_df,by="date")
sonar_data<-sonar_data%>%
rbind(sonar_dataC)
suppressMessages(library(nnet))
# Split data into training and testing sets
set.seed(Sys.time()) #reset seed
iterations=100
results<-data.frame()
for(i in 1:iterations){
train_index <- createDataPartition(aux_data$species, p = 0.7, list = FALSE)
train_data <- aux_data[train_index, ]
test_data <- aux_data[-train_index, ]
#use multinom() call for multinomial regression
model_iter <- multinom(species ~ as.numeric(date) + length + Flow_cfs,
data = train_data)
test_data$species_predicted <- predict(model_iter, newdata = test_data)
accuracy <- sum(test_data$species_predicted ==
test_data$species)/nrow(test_data)
Ntrue_A<-sum(test_data$species=="A")
Ntrue_B<-sum(test_data$species=="B")
Ntrue_C<-sum(test_data$species=="C")
Nest_A<-sum(test_data$species_predicted=="A")
Nest_B<-sum(test_data$species_predicted=="B")
Nest_C<-sum(test_data$species_predicted=="C")
error_A <- abs(Nest_A - Ntrue_A)
error_B <- abs(Nest_B - Ntrue_B)
error_C <- abs(Nest_C - Ntrue_C)
rel_error_A <- error_A / Ntrue_A
rel_error_B <- error_B / Ntrue_B
rel_error_C <- error_C / Ntrue_C
MAPE <- mean(c(rel_error_A, rel_error_B, rel_error_C)) * 100
d<-data.frame("accuracy"=accuracy,"MAPE"=MAPE)
results<-results%>%rbind(d)
}
model_2<-multinom(species ~ as.numeric(date) + length + Flow_cfs,
data = aux_data)
sonar_data$species <- predict(model_2, newdata = sonar_data, type = "class")
# Plot the results
p_dates<-ggplot(sonar_data, aes(x = date, fill = species)) +
geom_histogram() +
labs(title = "Sonar Movement Data",
x = "Week",
y = "frequency") +
scale_fill_manual(values = c('maroon','darkgreen','lightblue'),
labels = c('A','B','C'))+
theme_classic()
p_lengths<-ggplot(sonar_data, aes(x = length, fill = species)) +
geom_histogram() +
labs(title = "Sonar Movement Data",
x = "length (cm)",
y = "frequency") +
scale_fill_manual(values = c('maroon','darkgreen','lightblue'),
labels = c('A','B','C'))+
theme_classic()
grid.arrange(p_dates, p_lengths)
N_est4<-sonar_data%>%
group_by(species)%>%
tally()
#bootstrapping boogie
iterations<-100
results<-data.frame()
for(j in 1:iterations){
d <- sonar_data[sample(nrow(sonar_data), replace = TRUE), ]
p_classes <- predict(model_2, newdata = d, type = "class")
sonar_boot<-d%>%cbind(p_classes)
N_A<-length(which(sonar_boot$p_classes=="A"))
N_B<-length(which(sonar_boot$p_classes=="B"))
N_C<-length(which(sonar_boot$p_classes=="C"))
iter<-data.frame('iteration'=j,"A"=N_A[1],"B"=N_B[1],"C"=N_C[1])
results<-results%>%rbind(iter)
}
#iteration total estimates
iter_totals<-results%>%
group_by(iteration)%>%
dplyr::summarise(A=sum(A),
B=sum(B),
C=sum(C))
#bounds
A_stats <- quantile(iter_totals$A, probs = c(0.025, 0.975))
B_stats <- quantile(iter_totals$B, probs = c(0.025, 0.975))
C_stats <- quantile(iter_totals$C, probs = c(0.025, 0.975))
saveRDS(aux_data,"data/aux_data.rds")
saveRDS(sonar_data,"data/sonar_data.rds")
saveRDS(flow_df,"data/flow_df.rds")
library(tidyverse) #for piping and data formatting ease
library(ggplot2) #for plotting
library(lubridate) #makes formatting dates a little easier
library(caret) #provides the createDataPartition() call for testing/training
library(nnet) #for multi-nomial regression
library(mclust) #for gaussian mixed models
sonar_data<-readRDS("data/sonar_data.rds")
aux_data<-readRDS("data/aux_data.rds")
flow_df<-readRDS("data/flow_df.rds")
cols=c('A'='maroon','B'='darkblue','C'='darkgreen')
shapes=c('A'=16,'B'=17,'C'=18)
ggplot(aux_data, aes(x=length, y=as.Date(date,origin="1970-01-01"),
color=species, shape=species)) +
geom_point(size=3) +
scale_color_manual(values = cols)+
scale_shape_manual(values = shapes)+
labs(title="Auxiliary data", x="Length", y="Date") +
theme_classic()
set.seed(Sys.time()) #reset seed
iterations=100
results<-data.frame()
gmm_data<-select(aux_data,length,date,Flow_cfs,species)
#note here that the Mclust requires date in a numeric format
gmm_data$num_date<-as.numeric(gmm_data$date)
for(i in 1:iterations){
train_index <- createDataPartition(gmm_data$species, p = 0.7, list = FALSE)
train_data <- gmm_data[train_index, ]
test_data <- gmm_data[-train_index, ]
Ntrue_A<-sum(test_data$species=="A")
Ntrue_B<-sum(test_data$species=="B")
Ntrue_C<-sum(test_data$species=="C")
#Fit a Gaussian Mixture Model to the training data
model_iter <- Mclust(train_data[, c("length", "num_date")], G=3)
#summary(model_iter)
# Predict species for the test data based on the trained model
predictions <- predict(model_iter, test_data[, c("length", "num_date")])
test_data$species_predicted <- factor(predictions$classification,
levels = 1:3, labels = c("A","B","C"))
accuracy <- sum(test_data$species_predicted ==
test_data$species)/nrow(test_data)
#Change in abundance estimate:
#here I can sum the probability for each classification to
#estimate total abundance
#instead of using the threshold classification method
Nest_A<-sum(predictions$z[,1])
Nest_B<-sum(predictions$z[,2])
Nest_C<-sum(predictions$z[,3])
error_A <- abs(Nest_A - Ntrue_A)
error_B <- abs(Nest_B - Ntrue_B)
error_C <- abs(Nest_C - Ntrue_C)
rel_error_A <- error_A / Ntrue_A
rel_error_B <- error_B / Ntrue_B
rel_error_C <- error_C / Ntrue_C
MAPE <- mean(c(rel_error_A, rel_error_B, rel_error_C)) * 100
d<-data.frame("accuracy"=accuracy,"MAPE"=MAPE)
results<-results%>%rbind(d)
}
library(tidyverse) #for piping and data formatting ease
library(ggplot2) #for plotting
library(lubridate) #makes formatting dates a little easier
library(caret) #provides the createDataPartition() call for testing/training
library(nnet) #for multi-nomial regression
library(mclust) #for gaussian mixed models
sonar_data<-readRDS("data/sonar_data2.rds")
sonar_data<-readRDS("data/sonar_data2.rds")
saveRDS(aux_data,"data/aux_data2.rds")
saveRDS(aux_data,"data/aux_data2.rds")
library(tidyverse) #for piping and data formatting ease
library(ggplot2) #for plotting
library(lubridate) #makes formatting dates a little easier
library(caret) #provides the createDataPartition() call for testing/training
library(nnet) #for multi-nomial regression
library(mclust) #for gaussian mixed models
sonar_data<-readRDS("data/sonar_data1.rds")
aux_data<-readRDS("data/aux_data1.rds")
flow_df<-readRDS("data/flow_df.rds")
#create new simulated auxiliary length and date for species C.
#lengths
lengths_C <- rnorm(150, mean=110, sd=10)
#dates
dates_C <- round(rnorm(150,mean = as.numeric(as.Date("2024-03-15")), sd = 20))
#make dataframe
aux_dataC <- data.frame(
length = c(lengths_C),
date = round(as.Date(dates_C,origin = "1970-01-01")),
species = factor(rep("C", times=150))
)
#join in flow we created in last section
aux_dataC<-aux_dataC%>%
dplyr::left_join(flow_df,by="date")
aux_data<-aux_data%>%
rbind(aux_dataC)
library(gridExtra)
library(scales)
p_dates<-ggplot(aux_data) +
# Histogram for Date
geom_histogram(aes(x = date, fill = species), bins = 40) +
theme_classic()+
scale_fill_manual(values = c('darkorange2','cyan3','darkgreen'),
labels = c('A','B','C'))+
scale_x_date(date_breaks = "2 month",
labels=date_format("%b-%Y"),
limits = as.Date(c(min(aux_data$date),max(aux_data$date))))
p_lengths<-ggplot(aux_data) +
# Histogram for Length
geom_histogram(aes(x = length, fill = species), bins = 40) +
theme_classic()+
scale_fill_manual(values = c('darkorange2','cyan3','darkgreen'),
labels = c('A','B','C'))
p_flow<-ggplot(flow_df) +
# Histogram for Flow Conditions
geom_line(aes(x = date,y=Flow_cfs),
stat='identity') +
scale_x_date(date_breaks = "2 month",
labels=date_format("%b-%Y"),
limits = as.Date(c(min(aux_data$date),max(aux_data$date))))+
theme_classic()+
ylab("flow (cfs)")
grid.arrange(p_dates, p_lengths, p_flow)
#Simulate some example sonar data
#lengths
lengths_C <- rnorm(300, mean=110, sd=10)
#dates
dates_C <- round(rnorm(300,mean = as.numeric(as.Date("2024-03-15")), sd = 20))
#make dataframe
sonar_dataC <- data.frame(
length = c(lengths_C),
date = round(as.Date(dates_C,origin = "1970-01-01"))
)
#join in flow we created in last section
sonar_dataC<-sonar_dataC%>%
dplyr::left_join(flow_df,by="date")
sonar_data<-sonar_data%>%
rbind(sonar_dataC)
suppressMessages(library(nnet))
# Split data into training and testing sets
set.seed(Sys.time()) #reset seed
iterations=100
results<-data.frame()
for(i in 1:iterations){
train_index <- createDataPartition(aux_data$species, p = 0.7, list = FALSE)
train_data <- aux_data[train_index, ]
test_data <- aux_data[-train_index, ]
#use multinom() call for multinomial regression
model_iter <- multinom(species ~ as.numeric(date) + length + Flow_cfs,
data = train_data)
test_data$species_predicted <- predict(model_iter, newdata = test_data)
accuracy <- sum(test_data$species_predicted ==
test_data$species)/nrow(test_data)
Ntrue_A<-sum(test_data$species=="A")
Ntrue_B<-sum(test_data$species=="B")
Ntrue_C<-sum(test_data$species=="C")
Nest_A<-sum(test_data$species_predicted=="A")
Nest_B<-sum(test_data$species_predicted=="B")
Nest_C<-sum(test_data$species_predicted=="C")
error_A <- abs(Nest_A - Ntrue_A)
error_B <- abs(Nest_B - Ntrue_B)
error_C <- abs(Nest_C - Ntrue_C)
rel_error_A <- error_A / Ntrue_A
rel_error_B <- error_B / Ntrue_B
rel_error_C <- error_C / Ntrue_C
MAPE <- mean(c(rel_error_A, rel_error_B, rel_error_C)) * 100
d<-data.frame("accuracy"=accuracy,"MAPE"=MAPE)
results<-results%>%rbind(d)
}
model_2<-multinom(species ~ as.numeric(date) + length + Flow_cfs,
data = aux_data)
sonar_data$species <- predict(model_2, newdata = sonar_data, type = "class")
# Plot the results
p_dates<-ggplot(sonar_data, aes(x = date, fill = species)) +
geom_histogram() +
labs(title = "Sonar Movement Data",
x = "Week",
y = "frequency") +
scale_fill_manual(values = c('maroon','darkgreen','lightblue'),
labels = c('A','B','C'))+
theme_classic()
p_lengths<-ggplot(sonar_data, aes(x = length, fill = species)) +
geom_histogram() +
labs(title = "Sonar Movement Data",
x = "length (cm)",
y = "frequency") +
scale_fill_manual(values = c('maroon','darkgreen','lightblue'),
labels = c('A','B','C'))+
theme_classic()
grid.arrange(p_dates, p_lengths)
N_est4<-sonar_data%>%
group_by(species)%>%
tally()
#bootstrapping boogie
iterations<-100
results<-data.frame()
for(j in 1:iterations){
d <- sonar_data[sample(nrow(sonar_data), replace = TRUE), ]
p_classes <- predict(model_2, newdata = d, type = "class")
sonar_boot<-d%>%cbind(p_classes)
N_A<-length(which(sonar_boot$p_classes=="A"))
N_B<-length(which(sonar_boot$p_classes=="B"))
N_C<-length(which(sonar_boot$p_classes=="C"))
iter<-data.frame('iteration'=j,"A"=N_A[1],"B"=N_B[1],"C"=N_C[1])
results<-results%>%rbind(iter)
}
#iteration total estimates
iter_totals<-results%>%
group_by(iteration)%>%
dplyr::summarise(A=sum(A),
B=sum(B),
C=sum(C))
#bounds
A_stats <- quantile(iter_totals$A, probs = c(0.025, 0.975))
B_stats <- quantile(iter_totals$B, probs = c(0.025, 0.975))
C_stats <- quantile(iter_totals$C, probs = c(0.025, 0.975))
library(tidyverse) #for piping and data formatting ease
library(ggplot2) #for plotting
library(lubridate) #makes formatting dates a little easier
library(caret) #provides the createDataPartition() call for testing/training
library(nnet) #for multi-nomial regression
library(mclust) #for gaussian mixed models
sonar_data<-readRDS("data/sonar_data1.rds")
aux_data<-readRDS("data/aux_data1.rds")
flow_df<-readRDS("data/flow_df.rds")
#create new simulated auxiliary length and date for species C.
#lengths
lengths_C <- rnorm(150, mean=110, sd=10)
#dates
dates_C <- round(rnorm(150,mean = as.numeric(as.Date("2024-03-15")), sd = 20))
#make dataframe
aux_dataC <- data.frame(
length = c(lengths_C),
date = round(as.Date(dates_C,origin = "1970-01-01")),
species = factor(rep("C", times=150))
)
#join in flow we created in last section
aux_dataC<-aux_dataC%>%
dplyr::left_join(flow_df,by="date")
aux_data<-aux_data%>%
rbind(aux_dataC)
library(gridExtra)
library(scales)
p_dates<-ggplot(aux_data) +
# Histogram for Date
geom_histogram(aes(x = date, fill = species), bins = 40) +
theme_classic()+
scale_fill_manual(values = c('darkorange2','cyan3','darkgreen'),
labels = c('A','B','C'))+
scale_x_date(date_breaks = "2 month",
labels=date_format("%b-%Y"),
limits = as.Date(c(min(aux_data$date),max(aux_data$date))))
p_lengths<-ggplot(aux_data) +
# Histogram for Length
geom_histogram(aes(x = length, fill = species), bins = 40) +
theme_classic()+
scale_fill_manual(values = c('darkorange2','cyan3','darkgreen'),
labels = c('A','B','C'))
p_flow<-ggplot(flow_df) +
# Histogram for Flow Conditions
geom_line(aes(x = date,y=Flow_cfs),
stat='identity') +
scale_x_date(date_breaks = "2 month",
labels=date_format("%b-%Y"),
limits = as.Date(c(min(aux_data$date),max(aux_data$date))))+
theme_classic()+
ylab("flow (cfs)")
grid.arrange(p_dates, p_lengths, p_flow)
#Simulate some example sonar data
#lengths
lengths_C <- rnorm(300, mean=110, sd=10)
#dates
dates_C <- round(rnorm(300,mean = as.numeric(as.Date("2024-03-15")), sd = 20))
#make dataframe
sonar_dataC <- data.frame(
length = c(lengths_C),
date = round(as.Date(dates_C,origin = "1970-01-01"))
)
#join in flow we created in last section
sonar_dataC<-sonar_dataC%>%
dplyr::left_join(flow_df,by="date")
sonar_data<-sonar_data%>%
rbind(sonar_dataC)
suppressMessages(library(nnet))
# Split data into training and testing sets
set.seed(Sys.time()) #reset seed
iterations=100
results<-data.frame()
for(i in 1:iterations){
train_index <- createDataPartition(aux_data$species, p = 0.7, list = FALSE)
train_data <- aux_data[train_index, ]
test_data <- aux_data[-train_index, ]
#use multinom() call for multinomial regression
model_iter <- multinom(species ~ as.numeric(date) + length + Flow_cfs,
data = train_data)
test_data$species_predicted <- predict(model_iter, newdata = test_data)
accuracy <- sum(test_data$species_predicted ==
test_data$species)/nrow(test_data)
Ntrue_A<-sum(test_data$species=="A")
Ntrue_B<-sum(test_data$species=="B")
Ntrue_C<-sum(test_data$species=="C")
Nest_A<-sum(test_data$species_predicted=="A")
Nest_B<-sum(test_data$species_predicted=="B")
Nest_C<-sum(test_data$species_predicted=="C")
error_A <- abs(Nest_A - Ntrue_A)
error_B <- abs(Nest_B - Ntrue_B)
error_C <- abs(Nest_C - Ntrue_C)
rel_error_A <- error_A / Ntrue_A
rel_error_B <- error_B / Ntrue_B
rel_error_C <- error_C / Ntrue_C
MAPE <- mean(c(rel_error_A, rel_error_B, rel_error_C)) * 100
d<-data.frame("accuracy"=accuracy,"MAPE"=MAPE)
results<-results%>%rbind(d)
}
model_2<-multinom(species ~ as.numeric(date) + length + Flow_cfs,
data = aux_data)
sonar_data$species <- predict(model_2, newdata = sonar_data, type = "class")
# Plot the results
p_dates<-ggplot(sonar_data, aes(x = date, fill = species)) +
geom_histogram() +
labs(title = "Sonar Movement Data",
x = "Week",
y = "frequency") +
scale_fill_manual(values = c('maroon','darkgreen','lightblue'),
labels = c('A','B','C'))+
theme_classic()
p_lengths<-ggplot(sonar_data, aes(x = length, fill = species)) +
geom_histogram() +
labs(title = "Sonar Movement Data",
x = "length (cm)",
y = "frequency") +
scale_fill_manual(values = c('maroon','darkgreen','lightblue'),
labels = c('A','B','C'))+
theme_classic()
grid.arrange(p_dates, p_lengths)
N_est4<-sonar_data%>%
group_by(species)%>%
tally()
#bootstrapping boogie
iterations<-100
results<-data.frame()
for(j in 1:iterations){
d <- sonar_data[sample(nrow(sonar_data), replace = TRUE), ]
p_classes <- predict(model_2, newdata = d, type = "class")
sonar_boot<-d%>%cbind(p_classes)
N_A<-length(which(sonar_boot$p_classes=="A"))
N_B<-length(which(sonar_boot$p_classes=="B"))
N_C<-length(which(sonar_boot$p_classes=="C"))
iter<-data.frame('iteration'=j,"A"=N_A[1],"B"=N_B[1],"C"=N_C[1])
results<-results%>%rbind(iter)
}
#iteration total estimates
iter_totals<-results%>%
group_by(iteration)%>%
dplyr::summarise(A=sum(A),
B=sum(B),
C=sum(C))
#bounds
A_stats <- quantile(iter_totals$A, probs = c(0.025, 0.975))
B_stats <- quantile(iter_totals$B, probs = c(0.025, 0.975))
C_stats <- quantile(iter_totals$C, probs = c(0.025, 0.975))
saveRDS(aux_data,"data/aux_data2.rds")
saveRDS(sonar_data,"data/sonar_data2.rds")
saveRDS(flow_df,"data/flow_df.rds")
library(tidyverse) #for piping and data formatting ease
library(ggplot2) #for plotting
library(lubridate) #makes formatting dates a little easier
library(caret) #provides the createDataPartition() call for testing/training
library(nnet) #for multi-nomial regression
library(mclust) #for gaussian mixed models
sonar_data<-readRDS("data/sonar_data2.rds")
aux_data<-readRDS("data/aux_data2.rds")
flow_df<-readRDS("data/flow_df.rds")
render

{"title":"Binomial Regression","markdown":{"yaml":{"title":"Binomial Regression","bibliography":"references/references.bib","link-citations":true},"headingText":"Create a sinusoidal flow pattern to simulate seasonal variation","containsRefs":false,"markdown":"\n\n```{r,echo=FALSE,message=FALSE,warning=FALSE}\nlibrary(tidyverse) #for piping and data formatting ease\nlibrary(ggplot2) #for plotting\nlibrary(lubridate) #makes formatting dates a little easier\nlibrary(caret) #provides the createDataPartition() call for testing/training\nlibrary(nnet) #for multi-nomial regression\nlibrary(mclust) #for gaussian mixed models\n```\n\nThe more auxiliary data we have available to us, the more complex, and\nhopefully accurate, of a model we can use to assign species to our sonar\ndata. Let's add some variables to our auxiliary data set, notably fish\nlength (cm) and daily flow data. For our example we'll just use one year\nof simulated auxiliary data, but you could use multiple years of\nauxiliary data to model speciation. We'll use similar methods as before,\nand can visualize the simulated data that we'll use here:\n\n```{r}\n#create new simulated auxiliary length, date, and flow data.\nset.seed(42)  # For reproducibility\n#lengths\nlengths_A <- round(rnorm(400, mean=100, sd=15),2)\nlengths_B <- round(rnorm(325, mean=80, sd=15),2)\n\n#dates\ndates_A <- round(rnorm(400,mean = as.numeric(as.Date(\"2023-11-20\")), sd = 20))\ndates_B <- round(rnorm(325,mean = as.numeric(as.Date(\"2024-01-10\")), sd = 22))\n\n#make dataframe\naux_data <- data.frame(\n  length = c(lengths_A, lengths_B),\n  date = round(as.Date(c(dates_A,dates_B), origin = \"1970-01-01\")),\n  species = factor(rep(c(\"A\", \"B\"), times=c(400,325)))\n)\n\n#flow\nstart_date <- as.Date(paste(year(min(aux_data$date)),\"01\",\"01\",sep=\"-\"))\nend_date <- as.Date(paste(year(max(aux_data$date)),\"12\",\"31\",sep=\"-\"))\ndates <- seq.Date(start_date, end_date, by = \"day\")\n\ndays_in_period <- length(dates)\nmax_flow <- 1000  # maximum flow in cfs\nmin_flow <- 100    # minimum flow in cfs\n\nflow_pattern <- (max_flow - min_flow) / 2 * \n  sin(2 * pi * (1:days_in_period -20) / 365) + \n  (max_flow + min_flow) / 2\n\n# Create a random noise process using an auto-regression model\n# rho=level of autocorrelation\nrho <- 0.9  # autocorrelation parameter; \n#higher values give smoother transitions\n\nac_noise <- numeric(days_in_period)\nac_noise[1] <- rnorm(1, mean = 0, sd = 100)  # initial noise value\nfor (i in 4:days_in_period) {\n  ac_noise[i] <- rho * ac_noise[i - 1] + rnorm(1, mean = 0, sd = 100)\n}\nflow_data <- flow_pattern + ac_noise\n\n# Ensure no flow goes below the minimum flow\nflow_data[flow_data < 10] <- 10\n\n# Create a dataframe for plotting and analysis\nflow_df <- data.frame(\n  date = as.Date(dates),\n  Flow_cfs = flow_data\n)\n\naux_data<-aux_data%>%\n  dplyr::left_join(flow_df,by=\"date\")\n```\n\n```{r regression_aux_plot,message=FALSE,warning=FALSE,echo=FALSE,fig.height=7,fig.width=5, fig.cap = \"Plots showing date, length, and flow for expanded simulated auxiliary data.\"}\nlibrary(gridExtra)\nlibrary(scales)\np_dates<-ggplot(aux_data) +\n  # Histogram for Date\n  geom_histogram(aes(x = date, fill = species), bins = 40) +\n  theme_classic()+\n  scale_fill_manual(values = c('darkorange2','cyan3'),\n                    labels = c('A','B'))+\n  scale_x_date(date_breaks = \"2 month\", \n                 labels=date_format(\"%b-%Y\"),\n                 limits = as.Date(c(min(aux_data$date),max(aux_data$date))))\n  \np_lengths<-ggplot(aux_data) +  \n  # Histogram for Length\n  geom_histogram(aes(x = length, fill = species), bins = 40) +\n  theme_classic()+\n  scale_fill_manual(values = c('darkorange2','cyan3'),\n                    labels = c('A','B'))\n  \np_flow<-ggplot(flow_df) +  \n  # Histogram for Flow Conditions\n  geom_line(aes(x = date,y=Flow_cfs),\n           stat='identity') +\n  scale_x_date(date_breaks = \"2 month\", \n                 labels=date_format(\"%b-%Y\"),\n                 limits = as.Date(c(min(aux_data$date),max(aux_data$date))))+\n  theme_classic()+\n  ylab(\"flow (cfs)\")\ngrid.arrange(p_dates, p_lengths, p_flow) \n```\n\nWe can use this auxiliary data to build a binomial **logistic\nregression** model, in which our response variable is the probability of\nthe observed fish being one of two species. This logistic regression\nmethod can allow us to incorporate additional covariates beyond just\ndate of capture. For our auxiliary data we can represent this model with\nthe following equation:\n\n$$ \nP(y=A)=\\frac{1}{1+e^{\\beta_0+\\beta_1*x_{1,y}+\\beta_2*x_{2,y}+....+\\beta_M*x_{M,y}}}\n$$ {#eq-binom_reg}\n\nWhere $P(y=A)$ is the probability of a given fish $y$ being species $A$,\n$\\beta$ is the regression coefficient for a given explanatory variable,\nand $M$ is the total number of explanatory variables. Here we'll be\nusing three potential explanatory variables: date of observation, fish\nlength (cm), and average daily water flow (cfs). This is similar to\nmethods outlined in @Metheny2012, where models were developed using live\nfish observations from the USGS Cooperative Fish and Wildlife Research\nUnit on Redwood Creek from 2009-2010.\n\nWe can build this model and validate it before we attempt to assign\nspecies to any sonar data. We can start by assigning a species index to\neach record, of 1 if the species was A, 0 if B. Then we can split our\ndata into a \"training\" data set to build the model on, and another data\nset to test the model on. We'll use the `createDataPartition()` function\nfrom the `caret` package to split our auxiliary data into the\n`train_data` data frame comprised of 70% of our records, and a\n`test_data` data frame comprising the other 30%.\n\n```{r, regression_model}\naux_index<-aux_data%>%\n  mutate(species_index=ifelse(aux_data$species==\"A\",1,0))\n\n# Split data into training and testing sets\nset.seed(123) #set seed for repeatability\n#create training data set with 70% of data\ntrain_index <- createDataPartition(aux_index$species,\n                                   p = 0.7, list = FALSE) \ntrain_data <- aux_index[train_index, ]\ntest_data <- aux_index[-train_index, ]\n```\n\nNow that we have our training and testing data sets, we can build our\nmodel with the `glm()` function, structuring it off of @eq-binom_reg,\nand setting as a binomial regression by setting `family=binomial`.\n\n```{r}\nmodel_1 <- glm(species_index ~ as.numeric(date) + length + Flow_cfs,\n               data = train_data, family = binomial)\nsummary(model_1)\n```\n\nIf we look at the summary output of our model, we can see that both\nlength and date have significant effects on the probability of a fish\nbeing species A or species B. The flow covariate was not significant in\nspecies ID, so we can actually drop it from our model moving forward.\n\n```{r}\nmodel_1 <- glm(species_index ~ as.numeric(date) + length,\n               data = train_data, family = binomial)\n```\n\nWe then use the `predict()` function to predict the species assignments\nof the `test_data` using the model we created. This assigns a\nprobability of each test record being species A, which we can then round\nand assign a value of 1 if that the probability is greater then 50%, and\n0 otherwise. This process is a \"threshold\" assignment, in which we\ncategorize our predicted probabilities into binary classes. Then those\npredictions are rejoined to the `test_data`.\n\n```{r}\n# Predictions\npredictions <- predict(model_1, newdata = test_data, type = \"response\")\npredicted_classes <- ifelse(predictions > 0.5, 1, 0)\nspecies_predicted<-ifelse(predicted_classes==1,\"A\",\"B\")\n\ntest_data<-test_data%>%cbind(species_predicted)\n```\n\nWe can now compare the predicted species for the `test_data` to the\nactual species, and see how accurate our species identification was\nusing this model.\n\n```{r}\n# Accuracy\naccuracy <- sum(species_predicted == test_data$species) / nrow(test_data)\nprint(paste(\"Accuracy:\", round(accuracy, 3)))\n```\n\nAbove we can see our estimate accuracy in determining if a given fish\nwas species A or B was `r round(accuracy,3)`. Of course, for our purpose\nwe are not necessarily interested in whether or not a given sonar fish\nimage is one species or another. What we are most interested in is\nabundances of each species based on our sonar data.\n\nTo figure out how much error there is in our estimates of the abundance\nfor each species we can find the true count for each species in our\n`test_data` and compare it to the abundance estimate based on the\nspecies predictions from the model.\n\n```{r}\nNtrue_A<-sum(test_data$species==\"A\")\nNtrue_B<-sum(test_data$species==\"B\")\n\nNest_A<-sum(test_data$species_predicted==\"A\")\nNest_B<-sum(test_data$species_predicted==\"B\")\n\nerror_A <- abs(Nest_A - Ntrue_A)\nerror_B <- abs(Nest_B - Ntrue_B)\n\nrel_error_A <- error_A / Ntrue_A\nrel_error_B <- error_B / Ntrue_B\n  \nMAPE <- mean(c(rel_error_A, rel_error_B)) * 100\n```\n\nWe see above that testing our model shows an error of\n`r paste(round(MAPE,3),\"%\")` in the our species abundance predictions.\n\nNext we'll want to do the above many more times in an iterative process\nsimilar to the bootstrapping we've already done, and we can use our\naverage relative error in abundance estimates as our benchmark.\n\n```{r}\nset.seed(Sys.time()) #reset seed\niterations=100\nresults<-data.frame()\nfor(i in 1:iterations){\n  train_index <- createDataPartition(aux_index$species,\n                                     p = 0.7, list = FALSE) \n  train_data <- aux_index[train_index, ]\n  test_data <- aux_index[-train_index, ]\n  model_iter <- glm(species_index ~ as.numeric(date) + length,\n               data = train_data, family = binomial)\n  predictions <- predict(model_iter, \n                         newdata = test_data, type = \"response\")\n  predicted_classes <- ifelse(predictions > 0.5, 1, 0)\n  species_predicted<-ifelse(predicted_classes==1,\"A\",\"B\")\n\n  test_data<-test_data%>%\n    cbind(species_predicted<-ifelse(predicted_classes==1,\"A\",\"B\"))\n  accuracy <- sum(species_predicted == test_data$species)/nrow(test_data)\n  \n  Ntrue_A<-sum(test_data$species==\"A\")\n  Ntrue_B<-sum(test_data$species==\"B\")\n\n  Nest_A<-sum(test_data$species_predicted==\"A\")\n  Nest_B<-sum(test_data$species_predicted==\"B\")\n\n  error_A <- abs(Nest_A - Ntrue_A)\n  error_B <- abs(Nest_B - Ntrue_B)\n\n  rel_error_A <- error_A / Ntrue_A\n  rel_error_B <- error_B / Ntrue_B\n  \n  MAPE <- mean(c(rel_error_A, rel_error_B)) * 100\n  \n  d<-data.frame(\"accuracy\"=accuracy,\"MAPE\"=MAPE)\n  results<-results%>%rbind(d)\n}\n```\n\nBased on the above model training and iterative testing, we see our\nmodel predicted the species of our test data with an average accuracy of\n`r round(mean(results$accuracy), 3)` and an average error in abundance\nestimates of `r paste(round(mean(results$MAPE),3),\"%\")`.\n\nWe've trained and tested our model, and have some benchmarks of accuracy\nin species ID and abundance estimates. Next we'll have to generate a new\nsonar data set for this example that will incorporate length and flow\ndata linked to our sonar counts. We can simulate this data similar to\nhow we've done for our prior two examples here:\n\n```{r, regression_sonar_sim}\n#Simulate some example sonar data\nset.seed(123)  # For reproducibility\n#lengths\nlengths_A <- round(rnorm(1000, mean=100, sd=15),2)\nlengths_B <- round(rnorm(850, mean=80, sd=15),2)\n\n#dates\ndates_A <- round(rnorm(1000,mean=as.numeric(as.Date(\"2023-11-10\")),sd=22))\ndates_B <- round(rnorm(850,mean=as.numeric(as.Date(\"2024-01-12\")),sd=20))\n\n#make dataframe\nsonar_data <- data.frame(\n  length = c(lengths_A, lengths_B),\n  date = round(as.Date(c(dates_A,dates_B), origin = \"1970-01-01\"))\n)\n\n#join in flow data\nsonar_data<-sonar_data%>%\n  dplyr::left_join(flow_df,by=\"date\")\n```\n\nNext we'll retrain our model using the entire auxiliary data set.\n\n```{r}\nmodel_1<-glm(species_index ~ as.numeric(date) + length + Flow_cfs,\n             data = aux_index, family = binomial)\n```\n\nBased on the summary output for our model, we see that length and date\nare both strong predictors of species, while the flow covariate is not\nsignificant in predicting species.\n\nNext we can use our `model_1` to assign species to our sonar data.\n\n```{r}\npredictions <- predict(model_1, newdata = sonar_data, type = \"response\")\npredicted_classes <- ifelse(predictions > 0.5, 1, 0)\n\nsonar_predicted<-sonar_data%>%cbind(predicted_classes)\nsonar_predicted$species=ifelse(sonar_predicted$predicted_classes==1,\"A\",\"B\")\n```\n\nPlot the speciation results.\n\n```{r, model1_plot,echo=FALSE, fig.cap = \"Plot showing species assignments of sonar data using binomial logistic regression.\"}\n# Plot the results\np_dates<-ggplot(sonar_predicted, aes(x = date, fill = species)) +\n  geom_histogram() +\n  labs(title = \"Sonar Movement Data\",\n       x = \"Week\",\n       y = \"frequency\") +\n  scale_fill_manual(values = c('maroon','darkgreen'),\n                    labels = c('A','B'))+\n  theme_classic()\n  \np_lengths<-ggplot(sonar_predicted, aes(x = length, fill = species)) +\n  geom_histogram() +\n  labs(title = \"Sonar Movement Data\",\n       x = \"length (cm)\",\n       y = \"frequency\") +\n  scale_fill_manual(values = c('maroon','darkgreen'),\n                    labels = c('A','B'))+\n  theme_classic()\n\ngrid.arrange(p_dates, p_lengths) \n```\n\n```{r}\nN_est3<-sonar_predicted%>%\n  group_by(species)%>%\n  tally()\n```\n\nOur final estimates of abundance in this example are `r N_est3[1,2]` for\nspecies A and `r N_est3[2,2]` for species B.\n\n## *Estimating uncertainty*\n\nWe can utilize a bootstrapping method again to incorporate variance in\nour sonar data and estimate confidence intervals for our final species\nabundance estimates. We'll do this by iteratively rebuilding our\nlogistic model by resampling our sonar data. The following chunk uses a\nfor-loop to sample, with replacement, our `sonar_data`, and then assign\nspecies using `model_1` to the new data set. We then calculate new\nestimates of abundance for each species with the same methods we just\nused.\n\n```{r}\n#bootstrapping boogie\niterations<-100\nresults<-data.frame()\n\nfor(j in 1:iterations){\n  d <- sonar_data[sample(nrow(sonar_data), replace = TRUE), ]\n  p_boot <- predict(model_1, newdata = d, type = \"response\")\n  p_classes <- ifelse(p_boot > 0.5, 1, 0)\n\n  sonar_boot<-sonar_data%>%cbind(p_classes)\n  sonar_boot$species=ifelse(sonar_boot$p_classes==1,\"A\",\"B\")\n  N_A<-length(which(sonar_boot$species==\"A\"))\n  N_B<-length(which(sonar_boot$species==\"B\"))\n  iter<-data.frame('iteration'=j,\"A\"=N_A[1],\"B\"=N_B[1])\n  results<-results%>%rbind(iter)\n}\n```\n\nWe can use the `results` output from above to calculate our 95%\nconfidence intervals using the `quantile()` call:\n\n```{r}\n#iteration total estimates\niter_totals<-results%>%\n  group_by(iteration)%>%\n  dplyr::summarise(A=sum(A),\n                   B=sum(B))\n\n#bounds\nA_stats <- quantile(iter_totals$A, probs = c(0.025, 0.975))\nB_stats <- quantile(iter_totals$B, probs = c(0.025, 0.975))\n```\n\nThe above results show that our estimate of total abundance of species A\nin our sonar counts is `r N_est3[1,2]` with 95% CI\n\\[`r ceiling(A_stats[1])`, `r ceiling(A_stats[2])`\\] and a count of\n`r N_est3[2,2]` with 95% CI \\[`r ceiling(B_stats[1])`,\n`r ceiling(B_stats[2])`\\] for species B.\n\nLogistic regression is a fairly simple method that can incorporate\nmultiple covariates to help in assigning species to sonar counts. A good\nadvantage of this method is we can train and test our logistic model\nwith our auxiliary data to estimate accuracy, and again bootstrap the\nsonar data to assign confidence intervals. Key assumption for the\nbinomial logistic regression include:\n\n-   All fish being speciated either one of two species.\n\n-   The dates of run times and lengths of fish observed in the auxiliary\n    data are representative of the fish observed in sonar imaging.\n\n```{r,echo=FALSE}\nsaveRDS(aux_data,\"data/aux_data1.rds\")\nsaveRDS(sonar_data,\"data/sonar_data1.rds\")\nsaveRDS(flow_df,\"data/flow_df.rds\")\n```\n","srcMarkdownNoYaml":"\n\n```{r,echo=FALSE,message=FALSE,warning=FALSE}\nlibrary(tidyverse) #for piping and data formatting ease\nlibrary(ggplot2) #for plotting\nlibrary(lubridate) #makes formatting dates a little easier\nlibrary(caret) #provides the createDataPartition() call for testing/training\nlibrary(nnet) #for multi-nomial regression\nlibrary(mclust) #for gaussian mixed models\n```\n\nThe more auxiliary data we have available to us, the more complex, and\nhopefully accurate, of a model we can use to assign species to our sonar\ndata. Let's add some variables to our auxiliary data set, notably fish\nlength (cm) and daily flow data. For our example we'll just use one year\nof simulated auxiliary data, but you could use multiple years of\nauxiliary data to model speciation. We'll use similar methods as before,\nand can visualize the simulated data that we'll use here:\n\n```{r}\n#create new simulated auxiliary length, date, and flow data.\nset.seed(42)  # For reproducibility\n#lengths\nlengths_A <- round(rnorm(400, mean=100, sd=15),2)\nlengths_B <- round(rnorm(325, mean=80, sd=15),2)\n\n#dates\ndates_A <- round(rnorm(400,mean = as.numeric(as.Date(\"2023-11-20\")), sd = 20))\ndates_B <- round(rnorm(325,mean = as.numeric(as.Date(\"2024-01-10\")), sd = 22))\n\n#make dataframe\naux_data <- data.frame(\n  length = c(lengths_A, lengths_B),\n  date = round(as.Date(c(dates_A,dates_B), origin = \"1970-01-01\")),\n  species = factor(rep(c(\"A\", \"B\"), times=c(400,325)))\n)\n\n#flow\nstart_date <- as.Date(paste(year(min(aux_data$date)),\"01\",\"01\",sep=\"-\"))\nend_date <- as.Date(paste(year(max(aux_data$date)),\"12\",\"31\",sep=\"-\"))\ndates <- seq.Date(start_date, end_date, by = \"day\")\n\ndays_in_period <- length(dates)\nmax_flow <- 1000  # maximum flow in cfs\nmin_flow <- 100    # minimum flow in cfs\n\n# Create a sinusoidal flow pattern to simulate seasonal variation\nflow_pattern <- (max_flow - min_flow) / 2 * \n  sin(2 * pi * (1:days_in_period -20) / 365) + \n  (max_flow + min_flow) / 2\n\n# Create a random noise process using an auto-regression model\n# rho=level of autocorrelation\nrho <- 0.9  # autocorrelation parameter; \n#higher values give smoother transitions\n\nac_noise <- numeric(days_in_period)\nac_noise[1] <- rnorm(1, mean = 0, sd = 100)  # initial noise value\nfor (i in 4:days_in_period) {\n  ac_noise[i] <- rho * ac_noise[i - 1] + rnorm(1, mean = 0, sd = 100)\n}\nflow_data <- flow_pattern + ac_noise\n\n# Ensure no flow goes below the minimum flow\nflow_data[flow_data < 10] <- 10\n\n# Create a dataframe for plotting and analysis\nflow_df <- data.frame(\n  date = as.Date(dates),\n  Flow_cfs = flow_data\n)\n\naux_data<-aux_data%>%\n  dplyr::left_join(flow_df,by=\"date\")\n```\n\n```{r regression_aux_plot,message=FALSE,warning=FALSE,echo=FALSE,fig.height=7,fig.width=5, fig.cap = \"Plots showing date, length, and flow for expanded simulated auxiliary data.\"}\nlibrary(gridExtra)\nlibrary(scales)\np_dates<-ggplot(aux_data) +\n  # Histogram for Date\n  geom_histogram(aes(x = date, fill = species), bins = 40) +\n  theme_classic()+\n  scale_fill_manual(values = c('darkorange2','cyan3'),\n                    labels = c('A','B'))+\n  scale_x_date(date_breaks = \"2 month\", \n                 labels=date_format(\"%b-%Y\"),\n                 limits = as.Date(c(min(aux_data$date),max(aux_data$date))))\n  \np_lengths<-ggplot(aux_data) +  \n  # Histogram for Length\n  geom_histogram(aes(x = length, fill = species), bins = 40) +\n  theme_classic()+\n  scale_fill_manual(values = c('darkorange2','cyan3'),\n                    labels = c('A','B'))\n  \np_flow<-ggplot(flow_df) +  \n  # Histogram for Flow Conditions\n  geom_line(aes(x = date,y=Flow_cfs),\n           stat='identity') +\n  scale_x_date(date_breaks = \"2 month\", \n                 labels=date_format(\"%b-%Y\"),\n                 limits = as.Date(c(min(aux_data$date),max(aux_data$date))))+\n  theme_classic()+\n  ylab(\"flow (cfs)\")\ngrid.arrange(p_dates, p_lengths, p_flow) \n```\n\nWe can use this auxiliary data to build a binomial **logistic\nregression** model, in which our response variable is the probability of\nthe observed fish being one of two species. This logistic regression\nmethod can allow us to incorporate additional covariates beyond just\ndate of capture. For our auxiliary data we can represent this model with\nthe following equation:\n\n$$ \nP(y=A)=\\frac{1}{1+e^{\\beta_0+\\beta_1*x_{1,y}+\\beta_2*x_{2,y}+....+\\beta_M*x_{M,y}}}\n$$ {#eq-binom_reg}\n\nWhere $P(y=A)$ is the probability of a given fish $y$ being species $A$,\n$\\beta$ is the regression coefficient for a given explanatory variable,\nand $M$ is the total number of explanatory variables. Here we'll be\nusing three potential explanatory variables: date of observation, fish\nlength (cm), and average daily water flow (cfs). This is similar to\nmethods outlined in @Metheny2012, where models were developed using live\nfish observations from the USGS Cooperative Fish and Wildlife Research\nUnit on Redwood Creek from 2009-2010.\n\nWe can build this model and validate it before we attempt to assign\nspecies to any sonar data. We can start by assigning a species index to\neach record, of 1 if the species was A, 0 if B. Then we can split our\ndata into a \"training\" data set to build the model on, and another data\nset to test the model on. We'll use the `createDataPartition()` function\nfrom the `caret` package to split our auxiliary data into the\n`train_data` data frame comprised of 70% of our records, and a\n`test_data` data frame comprising the other 30%.\n\n```{r, regression_model}\naux_index<-aux_data%>%\n  mutate(species_index=ifelse(aux_data$species==\"A\",1,0))\n\n# Split data into training and testing sets\nset.seed(123) #set seed for repeatability\n#create training data set with 70% of data\ntrain_index <- createDataPartition(aux_index$species,\n                                   p = 0.7, list = FALSE) \ntrain_data <- aux_index[train_index, ]\ntest_data <- aux_index[-train_index, ]\n```\n\nNow that we have our training and testing data sets, we can build our\nmodel with the `glm()` function, structuring it off of @eq-binom_reg,\nand setting as a binomial regression by setting `family=binomial`.\n\n```{r}\nmodel_1 <- glm(species_index ~ as.numeric(date) + length + Flow_cfs,\n               data = train_data, family = binomial)\nsummary(model_1)\n```\n\nIf we look at the summary output of our model, we can see that both\nlength and date have significant effects on the probability of a fish\nbeing species A or species B. The flow covariate was not significant in\nspecies ID, so we can actually drop it from our model moving forward.\n\n```{r}\nmodel_1 <- glm(species_index ~ as.numeric(date) + length,\n               data = train_data, family = binomial)\n```\n\nWe then use the `predict()` function to predict the species assignments\nof the `test_data` using the model we created. This assigns a\nprobability of each test record being species A, which we can then round\nand assign a value of 1 if that the probability is greater then 50%, and\n0 otherwise. This process is a \"threshold\" assignment, in which we\ncategorize our predicted probabilities into binary classes. Then those\npredictions are rejoined to the `test_data`.\n\n```{r}\n# Predictions\npredictions <- predict(model_1, newdata = test_data, type = \"response\")\npredicted_classes <- ifelse(predictions > 0.5, 1, 0)\nspecies_predicted<-ifelse(predicted_classes==1,\"A\",\"B\")\n\ntest_data<-test_data%>%cbind(species_predicted)\n```\n\nWe can now compare the predicted species for the `test_data` to the\nactual species, and see how accurate our species identification was\nusing this model.\n\n```{r}\n# Accuracy\naccuracy <- sum(species_predicted == test_data$species) / nrow(test_data)\nprint(paste(\"Accuracy:\", round(accuracy, 3)))\n```\n\nAbove we can see our estimate accuracy in determining if a given fish\nwas species A or B was `r round(accuracy,3)`. Of course, for our purpose\nwe are not necessarily interested in whether or not a given sonar fish\nimage is one species or another. What we are most interested in is\nabundances of each species based on our sonar data.\n\nTo figure out how much error there is in our estimates of the abundance\nfor each species we can find the true count for each species in our\n`test_data` and compare it to the abundance estimate based on the\nspecies predictions from the model.\n\n```{r}\nNtrue_A<-sum(test_data$species==\"A\")\nNtrue_B<-sum(test_data$species==\"B\")\n\nNest_A<-sum(test_data$species_predicted==\"A\")\nNest_B<-sum(test_data$species_predicted==\"B\")\n\nerror_A <- abs(Nest_A - Ntrue_A)\nerror_B <- abs(Nest_B - Ntrue_B)\n\nrel_error_A <- error_A / Ntrue_A\nrel_error_B <- error_B / Ntrue_B\n  \nMAPE <- mean(c(rel_error_A, rel_error_B)) * 100\n```\n\nWe see above that testing our model shows an error of\n`r paste(round(MAPE,3),\"%\")` in the our species abundance predictions.\n\nNext we'll want to do the above many more times in an iterative process\nsimilar to the bootstrapping we've already done, and we can use our\naverage relative error in abundance estimates as our benchmark.\n\n```{r}\nset.seed(Sys.time()) #reset seed\niterations=100\nresults<-data.frame()\nfor(i in 1:iterations){\n  train_index <- createDataPartition(aux_index$species,\n                                     p = 0.7, list = FALSE) \n  train_data <- aux_index[train_index, ]\n  test_data <- aux_index[-train_index, ]\n  model_iter <- glm(species_index ~ as.numeric(date) + length,\n               data = train_data, family = binomial)\n  predictions <- predict(model_iter, \n                         newdata = test_data, type = \"response\")\n  predicted_classes <- ifelse(predictions > 0.5, 1, 0)\n  species_predicted<-ifelse(predicted_classes==1,\"A\",\"B\")\n\n  test_data<-test_data%>%\n    cbind(species_predicted<-ifelse(predicted_classes==1,\"A\",\"B\"))\n  accuracy <- sum(species_predicted == test_data$species)/nrow(test_data)\n  \n  Ntrue_A<-sum(test_data$species==\"A\")\n  Ntrue_B<-sum(test_data$species==\"B\")\n\n  Nest_A<-sum(test_data$species_predicted==\"A\")\n  Nest_B<-sum(test_data$species_predicted==\"B\")\n\n  error_A <- abs(Nest_A - Ntrue_A)\n  error_B <- abs(Nest_B - Ntrue_B)\n\n  rel_error_A <- error_A / Ntrue_A\n  rel_error_B <- error_B / Ntrue_B\n  \n  MAPE <- mean(c(rel_error_A, rel_error_B)) * 100\n  \n  d<-data.frame(\"accuracy\"=accuracy,\"MAPE\"=MAPE)\n  results<-results%>%rbind(d)\n}\n```\n\nBased on the above model training and iterative testing, we see our\nmodel predicted the species of our test data with an average accuracy of\n`r round(mean(results$accuracy), 3)` and an average error in abundance\nestimates of `r paste(round(mean(results$MAPE),3),\"%\")`.\n\nWe've trained and tested our model, and have some benchmarks of accuracy\nin species ID and abundance estimates. Next we'll have to generate a new\nsonar data set for this example that will incorporate length and flow\ndata linked to our sonar counts. We can simulate this data similar to\nhow we've done for our prior two examples here:\n\n```{r, regression_sonar_sim}\n#Simulate some example sonar data\nset.seed(123)  # For reproducibility\n#lengths\nlengths_A <- round(rnorm(1000, mean=100, sd=15),2)\nlengths_B <- round(rnorm(850, mean=80, sd=15),2)\n\n#dates\ndates_A <- round(rnorm(1000,mean=as.numeric(as.Date(\"2023-11-10\")),sd=22))\ndates_B <- round(rnorm(850,mean=as.numeric(as.Date(\"2024-01-12\")),sd=20))\n\n#make dataframe\nsonar_data <- data.frame(\n  length = c(lengths_A, lengths_B),\n  date = round(as.Date(c(dates_A,dates_B), origin = \"1970-01-01\"))\n)\n\n#join in flow data\nsonar_data<-sonar_data%>%\n  dplyr::left_join(flow_df,by=\"date\")\n```\n\nNext we'll retrain our model using the entire auxiliary data set.\n\n```{r}\nmodel_1<-glm(species_index ~ as.numeric(date) + length + Flow_cfs,\n             data = aux_index, family = binomial)\n```\n\nBased on the summary output for our model, we see that length and date\nare both strong predictors of species, while the flow covariate is not\nsignificant in predicting species.\n\nNext we can use our `model_1` to assign species to our sonar data.\n\n```{r}\npredictions <- predict(model_1, newdata = sonar_data, type = \"response\")\npredicted_classes <- ifelse(predictions > 0.5, 1, 0)\n\nsonar_predicted<-sonar_data%>%cbind(predicted_classes)\nsonar_predicted$species=ifelse(sonar_predicted$predicted_classes==1,\"A\",\"B\")\n```\n\nPlot the speciation results.\n\n```{r, model1_plot,echo=FALSE, fig.cap = \"Plot showing species assignments of sonar data using binomial logistic regression.\"}\n# Plot the results\np_dates<-ggplot(sonar_predicted, aes(x = date, fill = species)) +\n  geom_histogram() +\n  labs(title = \"Sonar Movement Data\",\n       x = \"Week\",\n       y = \"frequency\") +\n  scale_fill_manual(values = c('maroon','darkgreen'),\n                    labels = c('A','B'))+\n  theme_classic()\n  \np_lengths<-ggplot(sonar_predicted, aes(x = length, fill = species)) +\n  geom_histogram() +\n  labs(title = \"Sonar Movement Data\",\n       x = \"length (cm)\",\n       y = \"frequency\") +\n  scale_fill_manual(values = c('maroon','darkgreen'),\n                    labels = c('A','B'))+\n  theme_classic()\n\ngrid.arrange(p_dates, p_lengths) \n```\n\n```{r}\nN_est3<-sonar_predicted%>%\n  group_by(species)%>%\n  tally()\n```\n\nOur final estimates of abundance in this example are `r N_est3[1,2]` for\nspecies A and `r N_est3[2,2]` for species B.\n\n## *Estimating uncertainty*\n\nWe can utilize a bootstrapping method again to incorporate variance in\nour sonar data and estimate confidence intervals for our final species\nabundance estimates. We'll do this by iteratively rebuilding our\nlogistic model by resampling our sonar data. The following chunk uses a\nfor-loop to sample, with replacement, our `sonar_data`, and then assign\nspecies using `model_1` to the new data set. We then calculate new\nestimates of abundance for each species with the same methods we just\nused.\n\n```{r}\n#bootstrapping boogie\niterations<-100\nresults<-data.frame()\n\nfor(j in 1:iterations){\n  d <- sonar_data[sample(nrow(sonar_data), replace = TRUE), ]\n  p_boot <- predict(model_1, newdata = d, type = \"response\")\n  p_classes <- ifelse(p_boot > 0.5, 1, 0)\n\n  sonar_boot<-sonar_data%>%cbind(p_classes)\n  sonar_boot$species=ifelse(sonar_boot$p_classes==1,\"A\",\"B\")\n  N_A<-length(which(sonar_boot$species==\"A\"))\n  N_B<-length(which(sonar_boot$species==\"B\"))\n  iter<-data.frame('iteration'=j,\"A\"=N_A[1],\"B\"=N_B[1])\n  results<-results%>%rbind(iter)\n}\n```\n\nWe can use the `results` output from above to calculate our 95%\nconfidence intervals using the `quantile()` call:\n\n```{r}\n#iteration total estimates\niter_totals<-results%>%\n  group_by(iteration)%>%\n  dplyr::summarise(A=sum(A),\n                   B=sum(B))\n\n#bounds\nA_stats <- quantile(iter_totals$A, probs = c(0.025, 0.975))\nB_stats <- quantile(iter_totals$B, probs = c(0.025, 0.975))\n```\n\nThe above results show that our estimate of total abundance of species A\nin our sonar counts is `r N_est3[1,2]` with 95% CI\n\\[`r ceiling(A_stats[1])`, `r ceiling(A_stats[2])`\\] and a count of\n`r N_est3[2,2]` with 95% CI \\[`r ceiling(B_stats[1])`,\n`r ceiling(B_stats[2])`\\] for species B.\n\nLogistic regression is a fairly simple method that can incorporate\nmultiple covariates to help in assigning species to sonar counts. A good\nadvantage of this method is we can train and test our logistic model\nwith our auxiliary data to estimate accuracy, and again bootstrap the\nsonar data to assign confidence intervals. Key assumption for the\nbinomial logistic regression include:\n\n-   All fish being speciated either one of two species.\n\n-   The dates of run times and lengths of fish observed in the auxiliary\n    data are representative of the fish observed in sonar imaging.\n\n```{r,echo=FALSE}\nsaveRDS(aux_data,\"data/aux_data1.rds\")\nsaveRDS(sonar_data,\"data/sonar_data1.rds\")\nsaveRDS(flow_df,\"data/flow_df.rds\")\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"binomial_regression.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","editor":"visual","theme":"cosmo","title":"Binomial Regression","bibliography":["references/references.bib"],"link-citations":true},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}